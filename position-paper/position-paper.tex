\documentclass[sigplan]{acmart}

\usepackage[T1]{fontenc}
\usepackage{ucs}
\usepackage[utf8]{inputenc}

\usepackage{acronym} % \ac[p], \acl[p], \acs[p], \acf[p]
\usepackage{graphicx}
\usepackage{color}
\AtBeginDocument{
\definecolor{pdfurlcolor}{rgb}{0,0,0}
\definecolor{pdfcitecolor}{rgb}{0,0,0}
\definecolor{pdflinkcolor}{rgb}{0,0,0}
\definecolor{light}{gray}{.85}
\definecolor{vlight}{gray}{.95}
\definecolor{darkgreen}{rgb}{0.0, 0.2, 0.13}
}
\usepackage{booktabs}


\usepackage[draft,inline,nomargin,index]{fixme}
\fxsetup{theme=colorsig,mode=multiuser,inlineface=\itshape,envface=\itshape}
\FXRegisterAuthor{go}{ago}{Gerald}
\FXRegisterAuthor{mn}{amn}{Matthieu}

% Copyright
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% DOI
% \acmDOI{10.475/123_4}

% Acronyms
% --------
\acrodef{CRDT}[CRDT]{Conflict-free Replicated Data Type}
\acrodefplural{CRDT}[CRDTs]{Conflict-free Replicated Data Types}

% Meta-Data
% ---------

\hypersetup{pdftitle={Efficient renaming in CRDT},
    pdfsubject={},
    pdfkeywords={Data replication, CRDT},
    pdfauthor={M. Nicolas, O. Perrin, G. Oster}}

%\pagestyle{empty}

\begin{document}

\title{Efficient renaming in \acp{CRDT}}
\author{Matthieu Nicolas}
\affiliation{%
    \institution{Université de Lorraine, CNRS, Inria, LORIA}
    \postcode{F-54500}
    \country{France}
}
\email{matthieu.nicolas@inria.fr}

\renewcommand{\shortauthors}{M. Nicolas}

\begin{abstract}
   \mnnote{TODO: Write abstract}
\end{abstract}

\maketitle

\section{Research Statement}

In order to serve an ever-growing number of users and provide an increasing volume of data,
large scale systems such as data stores or collaborative editing tools adopt a distributed and replicated architecture.
However, as stated by the CAP theorem \cite{brewer_2000_podc}, such systems cannot ensure both strong consistency and high availability in presence of network partitions.
As a result, literature and companies increasingly adopt an optimistic replication model \cite{saito_2005_optimistic-replication} paired with the eventual consistency model to replicate data among nodes.
This consistency model allows replicas to temporarily diverge to be able to ensure high availability, even in case of network partition.
Each node owns a copy of the data and can modify it before propagating updates to others.
A conflict resolution mechanism is however required to handle updates generated concurrently by different nodes.

An approach, which gains in popularity since a few years, proposes to define \acfp{CRDT} \cite{shapiro_2011_crdt}.
These data types behave as traditional ones, such as the \emph{Set} or \emph{Sequence} data type, but are designed for a distributed usage.
Their specification ensures that concurrent updates are resolved deterministically, without requiring any kind of agreement, and that replicas eventually converge immediately after observing some set of updates,
thus achieving \emph{Strong Eventual Consistency} \cite{shapiro_2011_crdt}.

To achieve convergence, \acp{CRDT} proposed in the literature mostly rely on unique identifiers to reference updated elements.
To generate such element identifiers, nodes often use their own identifier combined with a logical clock.
Thus, regarding how node identifiers are generated, the size of element identifiers usually increases with the number of nodes.
Element identifiers have also to comply to additional constraints according to the \ac{CRDT}, for instance forming a dense set in the case of a \emph{Sequence} data type.
Consequently, the size of element identifiers also increases according to the number of updates performed on the data structure.
Therefore, the size of element identifiers is usually not bounded.

Since the size of identifiers attached to each element is not bounded, the overhead of the replicated data structure increases over time.
Since nodes have to store and broadcast these identifiers, the application's performances and efficiency decrease over time.
This severly impedes the adoption of concerned \acp{CRDT}.

In this thesis, we aim to address this issue of the growth of identifiers for a specific category of \acp{CRDT} suffering particularly from this issue:\emph{Sequence} \acp{CRDT}.

\section{Related Work}

The \emph{Sequence} data type represents an ordered collection elements.

Two operations are usually defined to update the sequence:
\emph{insert(index, element)} adds the \emph{element} at the given \emph{index}
whereas \emph{delete(index)} removes the element at the given \emph{index}.

This data type is often used in applications and, over the years, several \acp{CRDT} \cite{shapiro:inria-00177693, WeissICDCS09, AndreCollaborateCom2013} were proposed to represent replicated sequences. \mnnote{TODO: Aborder brièvement l'approche avec les tombstones (WOOT, RGA, RGASplit) et l'approche avec identifiants totalement ordonnés}
To ensure convergence, these data structures attach an identifier to each inserted element.
These identifiers are used to achieve transaction-less and commutative updates by uniquely identifying each element and ordering them relatively to each others.

The downside of this approach is the increasing size of identifiers.
Since identifiers are used to order elements, they have to form a dense set so that nodes are always able to insert a new element between two others.
However, two identifiers of the same size can be contiguous.
When inserting a new element between two such identifiers, there is no other choice than to increase the size of the generated identifier to be able to generate one respecting the intended order. This leads to a specification of identifiers which does not bound their size.

Several approaches were proposed in the literature in order to address the issue of evergrowing identifiers.
\citet{nedelec_2013_lseq} propose several strategies to generate identifiers and design a mechanism to switch between these strategies to limit the speed of the identifiers growth.
\citet{leia:inria-00397981} propose a renaming mechanism to reduce the size of currently used identifiers, relying on a consensus algorithm.
To prevent a system-wide consensus, authors divide the system into two tiers: the \emph{Core}, a small set of controlled and stable nodes, and the \emph{Nebula}, an uncontrolled set of nodes.
Both can perform updates but only the members of the \emph{Core} participate in the consensus leading to a rename.
A catch-up mechanism is provided for the \emph{Nebula} to transform the updates performed concurrently to a renaming.

Nonetheless, using consensuses is expensive and is not suited to all kind of application. In a fully distributed application, there is no central authority able to provide a set of stable nodes acting as the \emph{Core}. A fully distributed and efficient renaming mechanism is thus needed.

\section{Proposed Approach}
% \section{Statement explaining the approach and results, according to PhD stage: state the intended approach including a summary of work accomplished to date (if any).}

% \begin{itemize}
%     \item Defined properties that renaming functions need to comply to (commutative with insert/delete, a rename can be undone, do not shuffle the order)
%     \item Designed corresponding functions
%     \item Designed a new version of LogootSplit integrating them
% \end{itemize}

We propose a fully distributed renaming mechanism, allowing any node to perform a renaming without any kind of coordination with others.
The goal of such mechanism is to reassign shorter identifiers to each current element of the data structure to reduce its footprint.

We define a new operation : \emph{rename}.
This operation generates a new, equivalent state of the current sequence but with arbitrary identifiers of minimal size.
A map, called \emph{renamingMap}, is also generated to link each identifier from the former sequence to the corresponding identifier in the new one.
By propagating this map, other nodes are able to apply the same renaming to their own local copy.
\mnnote{NOTE: Mentionner qu'une \emph{renamingMap} n'est utilisée que pour renommer et qu'elle peut donc être transférée en BDD à un moment ? (causal stability ou sinon simple timeout sans l'utiliser)}

However, being a distributed system, nodes can perform updates and broadcast them while another node is performing concurrently the renaming process.
Upon the reception of these concurrent updates, the node which triggered the renaming process cannot apply them to its copy.
Indeed, since the identifiers have been modified, performing the updates would not insert the elements at the correct positions nor delete the correct elements.
To address this issue, we designed rewriting rules for concurrent operations to a \emph{rename}.
By using the original identifier and the \emph{renamingMap}, we are either able to find the new corresponding identifier, if it has been renamed, either able to deterministically generate a new identifier preserving the existing order, if it has been concurrently inserted.
The same set of rules can be used by nodes to compute their locale state upon the reception of a \emph{rename} operation.

However, one \emph{rename} operation can be concurrent to another one.
To solve this scenario, we give priority to one operation over the others.
Nodes which observed and applied one of the "losing" \emph{renaming} operations have to undo its effect before applying the "winning" one.
Thus we designed additional rewriting rules which reverse the effect of a previously applied \emph{rename} while also generating new identifiers preserving the order for identifiers generated after the renaming.
To determine which \emph{rename} operation to proceed with, we define and use a total order between \emph{rename} operations.

Based on this approach, we propose a new version of the LogootSplit \cite{AndreCollaborateCom2013} algorithm implementing this renaming mechanism.
\mnnote{TODO: Présenter brièvement LogootSplit}
We also introduce an optimisation to reduce the bandwidth consumption of the \emph{rename} operation by compressing the \emph{renamingMap}.

\section{Ongoing Validation}

The designed renaming mechanism has been implemented in MUTE \cite{nicolas:hal-01655438}, the realtime peer-to-peer collaborative text editor developed by our research team.
It is now in the process of being tested.

We are thus taking steps to provide a formal proof of the algorithm, either using a proof assistant either using a automatic theorem prover.

Although the renaming mechanism is bound to reduce the memory usage of the data structure over time, we need to assess that the additional computations do not degrade the overall performances of the application.
We are thus designing a benchmarker for collaborative editing tools.
The goal is to replay a collaborative editing session, from its logs, using different conflicts resolution mechanisms to compare their respective performances.
We intend to mesure common metrics like the memory and CPU usage, bandwith consumption but also more specific metrics like the time to propagate and integrate an update and the global time required to converge.

\section{Conclusion and Future Work}

The proposed renaming mechanism allows us to set a bound to the size of the identifiers.
By bounding the size of identifiers, we open new perspectives for the adoption of concerned \acp{CRDT} in system like distributed databases.

Nonetheless, several aspects of the proposed renaming mechanism can be enhanced.
The strategy used to determine when to trigger a renaming for example.
New strategies could be proposed to achieve better performances, by keeping the size of identifiers low while preventing many \emph{rename} operations to be generated concurrently.
The strategy used to determine which operation to apply in case of concurrent \emph{rename} operations could also be reworked. Smarter indicators than the total order between operations could be used to reduce the number of undo to perform globally and increase the overall performances.

\bibliographystyle{ACM-Reference-Format}
\bibliography{ref}

\end{document}
