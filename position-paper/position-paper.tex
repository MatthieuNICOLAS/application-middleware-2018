\documentclass[sigplan]{acmart}

\usepackage[T1]{fontenc}
\usepackage{ucs}
\usepackage[utf8]{inputenc}

\usepackage{acronym} % \ac[p], \acl[p], \acs[p], \acf[p]
\usepackage{graphicx}
\usepackage{color}
\AtBeginDocument{
\definecolor{pdfurlcolor}{rgb}{0,0,0}
\definecolor{pdfcitecolor}{rgb}{0,0,0}
\definecolor{pdflinkcolor}{rgb}{0,0,0}
\definecolor{light}{gray}{.85}
\definecolor{vlight}{gray}{.95}
\definecolor{darkgreen}{rgb}{0.0, 0.2, 0.13}
}
\usepackage{booktabs}


\usepackage[draft,inline,nomargin,index]{fixme}
\fxsetup{theme=colorsig,mode=multiuser,inlineface=\itshape,envface=\itshape}
\FXRegisterAuthor{go}{ago}{Gerald}
\FXRegisterAuthor{mn}{amn}{Matthieu}

% Copyright
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% DOI
% \acmDOI{10.475/123_4}

% Acronyms
% --------
\acrodef{CRDT}[CRDT]{Conflict-free Replicated Data Type}
\acrodefplural{CRDT}[CRDTs]{Conflict-free Replicated Data Types}

% Meta-Data
% ---------

\hypersetup{pdftitle={Efficient renaming in CRDT},
    pdfsubject={},
    pdfkeywords={Data replication, CRDT},
    pdfauthor={M. Nicolas, O. Perrin, G. Oster}}

%\pagestyle{empty}

\begin{document}

\title{Efficient renaming in \acp{CRDT}}
\author{Matthieu Nicolas}
\affiliation{%
    \institution{Université de Lorraine, CNRS, Inria, LORIA}
    \postcode{F-54500}
    \country{France}
}
\email{matthieu.nicolas@inria.fr}

\renewcommand{\shortauthors}{M. Nicolas}

\begin{abstract}
    % \mnnote{TO REVIEW: Write abstract}
    \emph{Sequence Conflict-free Replicated Data Types (CRDTs)} allow to replicate and edit, without any kind of coordination, sequences in distributed systems.
    To ensure convergence, existing works from the literature add metadata to each element but they do not bound its footprint, which impedes their adoption.
    Several approaches were proposed to address this issue but they do not fit a fully distributed setting.
    In this paper, we present our ongoing work on the design and validation of a fully distributed renaming mechanism, setting a bound to the metadata's footprint.
    Addressing this issue opens new perspectives of adoption of these CRDTs in distributed applications.
\end{abstract}

\maketitle

\section{Research Statement}

In order to serve an ever-growing number of users and provide an increasing volume of data,
large-scale systems such as data stores or collaborative editing tools adopt a distributed and replicated architecture.
However, as stated by the CAP theorem \cite{brewer_2000_podc}, such systems cannot ensure both strong consistency and high availability in presence of network partitions.
As a result, literature and companies increasingly adopt an optimistic replication model \cite{saito_2005_optimistic-replication} paired with the eventual consistency model to replicate data among nodes.
This consistency model allows replicas to temporarily diverge to ensure high availability, even in case of network partition.
Each node owns a copy of the data and can modify it before propagating updates to others.
A conflict resolution mechanism is however required to handle updates generated concurrently by different nodes.

An approach, which gains in popularity since a few years, proposes to define \acfp{CRDT} \cite{shapiro_2011_crdt}.
These data types behave as traditional ones, such as the \emph{Set} or \emph{Sequence} data type, but are designed for a distributed usage.
Their specification ensures that concurrent updates are resolved deterministically, without requiring any kind of agreement, and that replicas eventually converge immediately after observing some set of updates,
thus achieving \emph{Strong Eventual Consistency} \cite{shapiro_2011_crdt}.

To achieve convergence, \acp{CRDT} proposed in the literature mostly rely on unique identifiers to reference updated elements.
To generate such element identifiers, nodes often use their own identifier combined with a logical clock.
Thus, regarding how node identifiers are generated, the size of element identifiers usually increases with the number of nodes.
Element identifiers also have to comply to additional constraints according to the \ac{CRDT}, for instance forming a dense set in the case of a \emph{Sequence} data type.
Consequently, the size of element identifiers also increases according to the number of updates performed on the data structure.
Therefore, the size of element identifiers is usually not bounded.

Since the size of identifiers attached to each element is not bounded, the overhead of the replicated data structure increases over time.
Since nodes have to store and broadcast these identifiers, the application's performances and efficiency decrease over time.
This severely impedes the adoption of concerned \acp{CRDT}.

In this thesis, we aim to address this issue of the growth of identifiers for a specific category of \acp{CRDT} suffering particularly from this issue: \emph{Sequence} \acp{CRDT}.

\section{Related Work}

The \emph{Sequence} data type represents an ordered collection elements.

Two operations are usually defined to update the sequence:
\emph{insert(index, element)} adds the \emph{element} at the given \emph{index}
whereas \emph{delete(index)} removes the element at the given \emph{index}.

This data type is often used in applications and, over the years, several \acp{CRDT} \cite{shapiro:inria-00555588} were proposed to represent replicated sequences, which can be divided into two approaches.

% \mnnote{TO REVIEW: Aborder brièvement l'approche avec les tombstones (WOOT, RGA, RGASplit) et l'approche avec identifiants totalement ordonnés}
The first one \cite{briot:hal-01343941} proposes to add to each element a timestamp and a reference to its predecessor.
Using these data, a total order between elements is defined.
However this approach requires to keep tombstones for deleted elements to handle concurrent insertions.

The second approach \cite{AndreCollaborateCom2013}, on which we focus from this point, proposes to attach an identifier to each inserted element.
These identifiers are used to achieve commutative updates by uniquely identifying each element and ordering them relatively to each other.
% We focus on this approach for the rest of this paper.

The downside of this approach is the increasing size of identifiers.
Since identifiers are used to order elements, they have to form a dense set so that nodes are always able to insert a new element between two others.
However, two identifiers of the same size can be contiguous.
When inserting a new element between two such identifiers, there is no other choice than to increase the size of the generated identifier to be able to generate one respecting the intended order. This leads to a specification of identifiers which does not bound their size.

Several approaches were proposed in the literature in order to address the issue of ever-growing identifiers.
\citet{nedelec_2013_lseq} propose several strategies to generate identifiers and design a mechanism to switch between these strategies to limit the speed of the identifiers growth.
\citet{leia:inria-00397981} propose a renaming mechanism to reduce the size of currently used identifiers, relying on a consensus algorithm.
To prevent a system-wide consensus, authors divide the system into two tiers: the \emph{Core}, a small set of controlled and stable nodes, and the \emph{Nebula}, an uncontrolled set of nodes.
Both can perform updates but only the members of the \emph{Core} participate in the consensus leading to a rename.
A catch-up mechanism is provided for the \emph{Nebula} to transform the updates performed concurrently.

Nonetheless, using consensuses is expensive and not suited to all kinds of applications. In a fully distributed application, there is no central authority to provide a set of stable nodes acting as the \emph{Core}. A efficient distributed renaming mechanism is thus needed.

\section{Proposed Approach}

We propose a fully distributed renaming mechanism, allowing any node to perform a renaming without any kind of coordination with others.
The goal of such mechanism is to reassign shorter identifiers to each current element of the data structure to reduce its footprint.

We define a new operation : \emph{rename}.
This operation generates a new, equivalent state of the current sequence but with arbitrary identifiers of minimal size.
A map, called \emph{renamingMap}, is also generated to link each identifier from the former sequence to the corresponding identifier in the new one.
By propagating this map, other nodes are able to apply the same renaming to their own local copy.
% \mnnote{TO REVIEW: Mentionner qu'une \emph{renamingMap} n'est utilisée que pour renommer et qu'elle peut donc être transférée en BDD à un moment ? (causal stability ou sinon simple timeout sans l'utiliser)}
The \emph{renamingMap} is only used for renaming, it can thus be garbage collected once the corresponding \emph{rename} operation has been observed by every node.

However, being a distributed system, nodes can perform updates and broadcast them while another node is performing concurrently the renaming process.
Upon the reception of these concurrent updates, the node which triggered the renaming process cannot apply them to its copy.
Indeed, since the identifiers have been modified, performing the updates would not insert the elements at the correct positions nor delete the correct elements.
To address this issue, we designed rewriting rules for concurrent operations to a \emph{rename}.
By using the original identifier and the \emph{renamingMap}, we are either able to find the new corresponding identifier, if it has been renamed, either able to deterministically generate a new identifier preserving the existing order, if it has been concurrently inserted.
The same set of rules can be used by nodes to compute their locale state upon the reception of \emph{rename} operations.

However, one \emph{rename} operation can be concurrent to another one.
To solve this scenario, we give priority to one operation over the others.
Nodes which observed and applied one of the "losing" \emph{renaming} operations have to undo its effect before applying the "winning" one.
Thus we designed additional rewriting rules which reverse the effect of a previously applied \emph{rename} while also generating new identifiers preserving the order for identifiers generated after the renaming.
To determine which \emph{rename} operation to proceed with, we define and use a total order between \emph{rename} operations.

Based on this approach, we propose a new version of the LogootSplit \cite{AndreCollaborateCom2013} algorithm implementing this renaming mechanism.
% \mnnote{TO REVIEW: Présenter brièvement LogootSplit}
LogootSplit is the state of art of Identifier-based Sequence \acp{CRDT}.
It reduces the footprint of the data structure by aggregating elements into blocks.
The renaming mechanism, paired to LogootSplit, allows us to reassign shorter identifiers to elements, but also to merge existing blocks into one, reducing even more the metadata used.
We also introduce an optimisation to reduce the bandwidth consumption of the \emph{rename} operation by compressing the \emph{renamingMap}.

\section{Ongoing Validation}

The proposed renaming mechanism has been implemented in MUTE \cite{nicolas:hal-01655438}, the real time peer-to-peer collaborative text editor developed by our research team.
It is now in the process of being tested.

We are also taking steps to provide a formal specification of the algorithm and prove its correctness, either using a proof assistant either using an automatic theorem prover.

Although the renaming mechanism is bound to reduce the memory usage of the data structure over time, we need to assess that the additional computations do not degrade the overall performances.
We are thus designing a benchmarker for collaborative editing tools.
The goal is to replay a collaborative editing session, from its logs, using different conflicts resolution mechanisms to compare their respective performances.
We intend to measure common metrics like the memory and CPU usage, bandwidth consumption but also more specific ones like the time to propagate and integrate an update and the global time needed to converge.

\section{Conclusion and Future Work}

The proposed renaming mechanism allows us to set a bound to the size of the identifiers.
By bounding the size of identifiers, we open new perspectives for the adoption of concerned \acp{CRDT} in systems like distributed databases.

Nonetheless, we are still working on several aspects of the proposed renaming mechanism.
The strategy used to trigger a renaming has yet to be designed and evaluated.
It should keep the size of identifiers low while preventing many \emph{rename} operations to be generated concurrently to achieve good performances.
We could also rework the strategy used to pick a "winning" operation from a set of concurrent \emph{rename} operations.
The current one, defining and using a total order between these operations, can lead to cases in which nodes have to undo many \emph{rename} operations because of only one concurrent operation.
This could provoke performance issues.
New strategies could be proposed to reduce the likelihood of these scenarios and improve the overall performances of the system.

\bibliographystyle{ACM-Reference-Format}
\bibliography{ref}

\end{document}
